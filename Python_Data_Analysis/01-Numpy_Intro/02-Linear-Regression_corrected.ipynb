{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression from scratch\n",
    "The goal of the exercise is here to implement a simple linear regression between two 1-dimensional variables from scratch using numpy.\n",
    "\n",
    "Let say that we want to predict the values of n points $y = \\{y_i\\}_i$ from the values of $x = \\{x_i\\}_i$ with a simple linear equation:\n",
    "\n",
    "\\\\[ \\hat{y_i} = b_1 . x_i  + b_0 \\\\]\n",
    "\n",
    "Where $\\hat{y_i}$ is the predicted value of $y_i$ knowing $x_i$, $b_1$ is called the slope and $b_0$ the intercept.\n",
    "\n",
    "The formula for the coefficients of a simple linear regression between x and y minimizing the mean squared error between $y$ and $\\hat{y}$ is given by: \n",
    "\n",
    "\n",
    "\\\\[ b_1 = \\frac{cov_{xy}}{var_{x}}\\\\]\n",
    "and \n",
    "\\\\[ b_0 = \\bar{y} - b_1 .\\bar{x} \\\\]\n",
    "\n",
    "With:\n",
    "- $\\bar{y} = \\sum_{i=1}^n{y_i} / n$ the empirical mean of $y$\n",
    "- $\\bar{x} = \\sum_{i=1}^n{x_i} / n$ the empirical mean of $x$\n",
    "- $cov_{xy} = \\sum_{i=1}^n{(x_i -\\bar{x})(y_i -\\bar{y})} / n$, the empirical covariance between x and y\n",
    "- $var_{x} = \\sum_{i=1}^n{(x_i -\\bar{x})^2} / n$, the variance of x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "A few helper functions for data loading and visualization are available in helpers.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import helpers\n",
    "# test the import by running  a dummy function\n",
    "helpers.print_hello()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = helpers.data_linear_regression[:, 0]\n",
    "y = helpers.data_linear_regression[:, 1]\n",
    "\n",
    "helpers.data_linear_regression  # The data we will be using here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = helpers.plot_linear_regression(x, y, slope=1., intercept=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "Fill in the following functions to obtain your implementation of a simple linear regression **without using loops**. You can define additional functions if you need to:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The very lazy solution (which is what you would do in real life)\n",
    "You could directly use [scipy's](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.linregress.html) (or [scikit's](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)) linear regression tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "# Compute the coefficients\n",
    "slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(x,y)\n",
    "# Visualization of the output\n",
    "fig, ax = helpers.plot_linear_regression(x, y, slope=slope, intercept=intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The semi lazy solution\n",
    "The covariance matrix between x and y can be directly computed using [np.cov](https://numpy.org/doc/stable/reference/generated/numpy.cov.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_slope(x, y):\n",
    "    \"Return the slope for a 1-dimensional linear regression\"\n",
    "    cov_matrix = np.cov(x, y)  # covariance matrix for x and y\n",
    "    slope = cov_matrix[0, 1] / cov_matrix[0, 0]\n",
    "    return slope\n",
    "    \n",
    "\n",
    "def compute_linear_regression(x, y):\n",
    "    \"Return the slope and the intercept for a 1-dimensional linear regression\"\n",
    "    slope = compute_slope(x, y)\n",
    "    intercept = y.mean() - slope * x.mean()\n",
    "    return slope, intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the output:\n",
    "slope, intercept = compute_linear_regression(x, y)\n",
    "\n",
    "fig, ax = helpers.plot_linear_regression(x, y, slope=slope, intercept=intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The solution for the bravest\n",
    "We can also compute the coefficient using only the basic operations available in numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mean1D(arr):\n",
    "    \"Return the mean of a 1-Dimensional array\"\n",
    "    return arr.sum() / len(arr)\n",
    "\n",
    "\n",
    "def cov1D(x, y):\n",
    "    \"\"\"Compute the covariance between two 1-dimensional arrays.\n",
    "\n",
    "    N.B. compute_cov(x, x) returns the variance of x.\n",
    "    \"\"\"\n",
    "    # Precomputation of the mean of the inputs\n",
    "    x_mean = mean1D(x)\n",
    "    y_mean = mean1D(y)\n",
    "    # Compute the covariance using its definition\n",
    "    return mean1D((x - x_mean) * (y - y_mean))\n",
    "\n",
    "\n",
    "def compute_slope(x, y):\n",
    "    \"Return the slope for a 1-dimensional linear regression\"\n",
    "    slope = cov1D(x, y) / cov1D(x, x)\n",
    "    return slope\n",
    "    \n",
    "\n",
    "def compute_linear_regression(x, y):\n",
    "    \"Return the slope and the intercept for a 1-dimensional linear regression\"\n",
    "    slope = compute_slope(x, y)\n",
    "    intercept = mean1D(y) - slope * mean1D(x)\n",
    "    return slope, intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the output:\n",
    "slope, intercept = compute_linear_regression(x, y)\n",
    "\n",
    "fig, ax = helpers.plot_linear_regression(x, y, slope=slope, intercept=intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To go further\n",
    "Additional tasks if you want to go further:\n",
    "- Compute the mean square error between the true value of y and the predicted value\n",
    "- Generalize the code to use a multidimensional x input (see the formula [here](https://www.hackerearth.com/practice/machine-learning/linear-regression/multivariate-linear-regression-1/tutorial/))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
